
import scipy.misc as misc
import torch
import copy
from torch.autograd import Variable
import numpy as np
import torch.nn as nn
import torch.nn.functional as F

from functools import reduce

class LambdaBase(nn.Sequential):
    def __init__(self, fn, *args):
        super(LambdaBase, self).__init__(*args)
        self.lambda_func = fn

    def forward_prepare(self, input):
        output = []
        for module in self._modules.values():
            output.append(module(input))
        return output if output else input

class Lambda(LambdaBase):
    def forward(self, input):
        return self.lambda_func(self.forward_prepare(input))

class LambdaMap(LambdaBase):
    def forward(self, input):
        return list(map(self.lambda_func,self.forward_prepare(input)))

class LambdaReduce(LambdaBase):
    def forward(self, input):
        return reduce(self.lambda_func,self.forward_prepare(input))


densenet_cosine_264_k32 = nn.Sequential( # Sequential,
	nn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),
	nn.BatchNorm2d(64),
        nn.ReLU(),
        nn.MaxPool2d((3, 3),(2, 2),(1, 1)),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(64),
			nn.ReLU(),
			nn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(96),
			nn.ReLU(),
			nn.Conv2d(96,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(160),
			nn.ReLU(),
			nn.Conv2d(160,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(192),
			nn.ReLU(),
			nn.Conv2d(192,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(224),
			nn.ReLU(),
			nn.Conv2d(224,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	nn.BatchNorm2d(256),
	nn.ReLU(),
	nn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
	nn.AvgPool2d((2, 2),(2, 2)),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(160),
			nn.ReLU(),
			nn.Conv2d(160,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(192),
			nn.ReLU(),
			nn.Conv2d(192,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(224),
			nn.ReLU(),
			nn.Conv2d(224,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(256),
			nn.ReLU(),
			nn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(288),
			nn.ReLU(),
			nn.Conv2d(288,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(320),
			nn.ReLU(),
			nn.Conv2d(320,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(352),
			nn.ReLU(),
			nn.Conv2d(352,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(384),
			nn.ReLU(),
			nn.Conv2d(384,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(416),
			nn.ReLU(),
			nn.Conv2d(416,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(448),
			nn.ReLU(),
			nn.Conv2d(448,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(480),
			nn.ReLU(),
			nn.Conv2d(480,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	nn.BatchNorm2d(512),
	nn.ReLU(),
	nn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),
	nn.AvgPool2d((2, 2),(2, 2)),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(256),
			nn.ReLU(),
			nn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(288),
			nn.ReLU(),
			nn.Conv2d(288,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(320),
			nn.ReLU(),
			nn.Conv2d(320,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(352),
			nn.ReLU(),
			nn.Conv2d(352,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(384),
			nn.ReLU(),
			nn.Conv2d(384,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(416),
			nn.ReLU(),
			nn.Conv2d(416,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(448),
			nn.ReLU(),
			nn.Conv2d(448,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(480),
			nn.ReLU(),
			nn.Conv2d(480,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(512),
			nn.ReLU(),
			nn.Conv2d(512,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(544),
			nn.ReLU(),
			nn.Conv2d(544,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(576),
			nn.ReLU(),
			nn.Conv2d(576,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(608),
			nn.ReLU(),
			nn.Conv2d(608,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(640),
			nn.ReLU(),
			nn.Conv2d(640,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(672),
			nn.ReLU(),
			nn.Conv2d(672,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(704),
			nn.ReLU(),
			nn.Conv2d(704,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(736),
			nn.ReLU(),
			nn.Conv2d(736,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(768),
			nn.ReLU(),
			nn.Conv2d(768,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(800),
			nn.ReLU(),
			nn.Conv2d(800,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(832),
			nn.ReLU(),
			nn.Conv2d(832,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(864),
			nn.ReLU(),
			nn.Conv2d(864,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(896),
			nn.ReLU(),
			nn.Conv2d(896,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(928),
			nn.ReLU(),
			nn.Conv2d(928,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(960),
			nn.ReLU(),
			nn.Conv2d(960,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(992),
			nn.ReLU(),
			nn.Conv2d(992,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1024),
			nn.ReLU(),
			nn.Conv2d(1024,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1056),
			nn.ReLU(),
			nn.Conv2d(1056,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1088),
			nn.ReLU(),
			nn.Conv2d(1088,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1120),
			nn.ReLU(),
			nn.Conv2d(1120,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1152),
			nn.ReLU(),
			nn.Conv2d(1152,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1184),
			nn.ReLU(),
			nn.Conv2d(1184,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1216),
			nn.ReLU(),
			nn.Conv2d(1216,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1248),
			nn.ReLU(),
			nn.Conv2d(1248,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1280),
			nn.ReLU(),
			nn.Conv2d(1280,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1312),
			nn.ReLU(),
			nn.Conv2d(1312,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1344),
			nn.ReLU(),
			nn.Conv2d(1344,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1376),
			nn.ReLU(),
			nn.Conv2d(1376,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1408),
			nn.ReLU(),
			nn.Conv2d(1408,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1440),
			nn.ReLU(),
			nn.Conv2d(1440,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1472),
			nn.ReLU(),
			nn.Conv2d(1472,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1504),
			nn.ReLU(),
			nn.Conv2d(1504,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1536),
			nn.ReLU(),
			nn.Conv2d(1536,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1568),
			nn.ReLU(),
			nn.Conv2d(1568,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1600),
			nn.ReLU(),
			nn.Conv2d(1600,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1632),
			nn.ReLU(),
			nn.Conv2d(1632,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1664),
			nn.ReLU(),
			nn.Conv2d(1664,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1696),
			nn.ReLU(),
			nn.Conv2d(1696,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1728),
			nn.ReLU(),
			nn.Conv2d(1728,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1760),
			nn.ReLU(),
			nn.Conv2d(1760,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1792),
			nn.ReLU(),
			nn.Conv2d(1792,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1824),
			nn.ReLU(),
			nn.Conv2d(1824,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1856),
			nn.ReLU(),
			nn.Conv2d(1856,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1888),
			nn.ReLU(),
			nn.Conv2d(1888,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1920),
			nn.ReLU(),
			nn.Conv2d(1920,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1952),
			nn.ReLU(),
			nn.Conv2d(1952,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1984),
			nn.ReLU(),
			nn.Conv2d(1984,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2016),
			nn.ReLU(),
			nn.Conv2d(2016,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2048),
			nn.ReLU(),
			nn.Conv2d(2048,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2080),
			nn.ReLU(),
			nn.Conv2d(2080,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2112),
			nn.ReLU(),
			nn.Conv2d(2112,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2144),
			nn.ReLU(),
			nn.Conv2d(2144,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2176),
			nn.ReLU(),
			nn.Conv2d(2176,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2208),
			nn.ReLU(),
			nn.Conv2d(2208,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2240),
			nn.ReLU(),
			nn.Conv2d(2240,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2272),
			nn.ReLU(),
			nn.Conv2d(2272,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	nn.BatchNorm2d(2304),
	nn.ReLU(),
	nn.Conv2d(2304,1152,(1, 1),(1, 1),(0, 0),1,1,bias=False),
	nn.AvgPool2d((2, 2),(2, 2)),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1152),
			nn.ReLU(),
			nn.Conv2d(1152,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1184),
			nn.ReLU(),
			nn.Conv2d(1184,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1216),
			nn.ReLU(),
			nn.Conv2d(1216,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1248),
			nn.ReLU(),
			nn.Conv2d(1248,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1280),
			nn.ReLU(),
			nn.Conv2d(1280,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1312),
			nn.ReLU(),
			nn.Conv2d(1312,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1344),
			nn.ReLU(),
			nn.Conv2d(1344,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1376),
			nn.ReLU(),
			nn.Conv2d(1376,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1408),
			nn.ReLU(),
			nn.Conv2d(1408,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1440),
			nn.ReLU(),
			nn.Conv2d(1440,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1472),
			nn.ReLU(),
			nn.Conv2d(1472,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1504),
			nn.ReLU(),
			nn.Conv2d(1504,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1536),
			nn.ReLU(),
			nn.Conv2d(1536,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1568),
			nn.ReLU(),
			nn.Conv2d(1568,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1600),
			nn.ReLU(),
			nn.Conv2d(1600,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1632),
			nn.ReLU(),
			nn.Conv2d(1632,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1664),
			nn.ReLU(),
			nn.Conv2d(1664,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1696),
			nn.ReLU(),
			nn.Conv2d(1696,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1728),
			nn.ReLU(),
			nn.Conv2d(1728,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1760),
			nn.ReLU(),
			nn.Conv2d(1760,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1792),
			nn.ReLU(),
			nn.Conv2d(1792,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1824),
			nn.ReLU(),
			nn.Conv2d(1824,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1856),
			nn.ReLU(),
			nn.Conv2d(1856,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1888),
			nn.ReLU(),
			nn.Conv2d(1888,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1920),
			nn.ReLU(),
			nn.Conv2d(1920,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1952),
			nn.ReLU(),
			nn.Conv2d(1952,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(1984),
			nn.ReLU(),
			nn.Conv2d(1984,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2016),
			nn.ReLU(),
			nn.Conv2d(2016,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2048),
			nn.ReLU(),
			nn.Conv2d(2048,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2080),
			nn.ReLU(),
			nn.Conv2d(2080,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2112),
			nn.ReLU(),
			nn.Conv2d(2112,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2144),
			nn.ReLU(),
			nn.Conv2d(2144,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2176),
			nn.ReLU(),
			nn.Conv2d(2176,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2208),
			nn.ReLU(),
			nn.Conv2d(2208,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2240),
			nn.ReLU(),
			nn.Conv2d(2240,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2272),
			nn.ReLU(),
			nn.Conv2d(2272,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2304),
			nn.ReLU(),
			nn.Conv2d(2304,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2336),
			nn.ReLU(),
			nn.Conv2d(2336,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2368),
			nn.ReLU(),
			nn.Conv2d(2368,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2400),
			nn.ReLU(),
			nn.Conv2d(2400,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2432),
			nn.ReLU(),
			nn.Conv2d(2432,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2464),
			nn.ReLU(),
			nn.Conv2d(2464,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2496),
			nn.ReLU(),
			nn.Conv2d(2496,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2528),
			nn.ReLU(),
			nn.Conv2d(2528,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2560),
			nn.ReLU(),
			nn.Conv2d(2560,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2592),
			nn.ReLU(),
			nn.Conv2d(2592,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2624),
			nn.ReLU(),
			nn.Conv2d(2624,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	LambdaReduce(lambda x,y,dim=1: torch.cat((x,y),dim), # Concat,
		Lambda(lambda x: x), # Identity,
		nn.Sequential( # Sequential,
			nn.BatchNorm2d(2656),
			nn.ReLU(),
			nn.Conv2d(2656,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),
			nn.BatchNorm2d(128),
			nn.ReLU(),
			nn.Conv2d(128,32,(3, 3),(1, 1),(1, 1),1,1,bias=False),
		),
	),
	nn.BatchNorm2d(2688),
	nn.ReLU(),
	nn.AvgPool2d((7, 7),(7, 7)),
	Lambda(lambda x: x.view(x.size(0),-1)), # Reshape,
	nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2688,1000)), # Linear,
)

class Net(nn.Module):# FCN Net class for semantic segmentation init generate net layers and forward run the inference
        def __init__(self,NumClasses,PreTrainedModelPath="",UseGPU=True,UpdateEncoderBatchNormStatistics=True): # prepare net layers and load Load pretrained encoder weights
            super(Net, self).__init__()
            self.UseGPU = UseGPU
            if not torch.cuda.is_available():
                self.UseGPU = False
#---------------Load Densenet pretrained encoder----------------------------------------------------------
            self.Encoder = densenet_cosine_264_k32
            if not PreTrainedModelPath=="":
                self.Encoder.load_state_dict(torch.load(PreTrainedModelPath)) #load densenet encoder pretrained weights
                print ("Dense net encoder weights loaded")
            if not UpdateEncoderBatchNormStatistics:
                self.Encoder.eval()# Weather or not to update batch statistics of encoder during training


            self.SkipConnectionLayers=[2,12,28,96]#,147]
#----------------PSP Layer (resize feature maps to  several scales, apply convolution resize back and concat) -------------------------------------------------------------------------
            self.PSPScales = [1, 1 / 2, 1 / 4, 1 / 8] # Resize scales

            self.PSPLayers = nn.ModuleList()  # [] # Layers for decoder
            for Ps in self.PSPScales:
                self.PSPLayers.append(nn.Sequential(
                    nn.Conv2d(2688, 1024, stride=1, kernel_size=3, padding=1, bias=True)))
                # nn.BatchNorm2d(1024)))
            self.PSPSqueeze = nn.Sequential(
                nn.Conv2d(4096, 512, stride=1, kernel_size=1, padding=0, bias=False),
                nn.BatchNorm2d(512),
                nn.ReLU()
            )
#------------------Skip conncetion pass layers from the encoder to layer from the decoder/upsampler after convolution-----------------------------------------------------------------------------
            self.SkipConnections = nn.ModuleList()
            self.SkipConnections.append(nn.Sequential(
                nn.Conv2d(1152, 512, stride=1, kernel_size=1, padding=0, bias=False),
                nn.BatchNorm2d(512),
                nn.ReLU()))
            self.SkipConnections.append(nn.Sequential(
                nn.Conv2d(256, 256, stride=1, kernel_size=1, padding=0, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU()))
# ------------------Skip squeeze concat of upsample+skip conncecion-----------------------------------------------------------------------------
            self.SqueezeUpsample = nn.ModuleList()
            self.SqueezeUpsample.append(nn.Sequential(
                nn.Conv2d(1024, 512, stride=1, kernel_size=1, padding=0, bias=False),
                nn.BatchNorm2d(512),
                nn.ReLU()
            ))
            self.SqueezeUpsample.append(nn.Sequential(
                nn.Conv2d(256+512, 256, stride=1, kernel_size=1, padding=0, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU()
            ))


#----------------Final prediction layer predict class per region/pixel------------------------------------------------------------------------------------------
            self.FinalPrdiction=nn.Conv2d(256, NumClasses, stride=1, kernel_size=3, padding=1, bias=False)
            if self.UseGPU==True:
                self=self.cuda()
##########################################################################################################################################################
        def forward(self,Images,EvalMode=False):

#----------------------Convert image to pytorch and normalize values-----------------------------------------------------------------
                RGBMean = [123.68,116.779,103.939]
                RGBStd = [65,65,65]
                if EvalMode==False: InpImages = torch.autograd.Variable(Images, requires_grad=False).transpose(2,3).transpose(1, 2).type(torch.FloatTensor)
                else: InpImages = torch.autograd.Variable(Images,requires_grad=False).transpose(2, 3).transpose(1, 2).type(torch.HalfTensor)

                if self.UseGPU == True:
                    InpImages=InpImages.cuda()

                for i in range(len(RGBMean)): InpImages[:, i, :, :]=(InpImages[:, i, :, :]-RGBMean[i])/RGBStd[i] # normalize image values
                x=InpImages
#--------------------Run Encoder------------------------------------------------------------------------------------------------------
                SkipConFeatures=[] # Store features map of layers used for skip connection
                for i in range(147): # run all layers of Encoder
                    x=self.Encoder[i](x)
                    if i in self.SkipConnectionLayers: # save output of specific layers used for skip conncections
                         SkipConFeatures.append(x)
                         #print("skip")
#------------------Run psp  decoder Layers----------------------------------------------------------------------------------------------
                PSPSize=(x.shape[2],x.shape[3]) # Size of the original features map

                PSPFeatures=[] # Results of various of scaled procceessing
                for i,Layer in enumerate(self.PSPLayers): # run PSP layers scale features map to various of sizes apply convolution and concat the results
                      NewSize=np.ceil(np.array(PSPSize)*self.PSPScales[i]).astype(np.int)
                      y = nn.functional.interpolate(x, tuple(NewSize), mode='bilinear')
                      #y = F.upsample(x, torch.from_numpy(NewSize), mode='bilinear')
                      y = Layer(y)
                      y = nn.functional.interpolate(y, PSPSize, mode='bilinear')
                #      if np.min(PSPSize*self.ScaleRates[i])<0.4: y*=0
                      PSPFeatures.append(y)
                x=torch.cat(PSPFeatures,dim=1)
                x=self.PSPSqueeze(x)
#----------------------------Upsample features map  and combine with layers from encoder using skip  connection-----------------------------------------------------------------------------------------------------------
                for i in range(len(self.SkipConnections)):
                  sp=(SkipConFeatures[-1-i].shape[2],SkipConFeatures[-1-i].shape[3])
                  x=nn.functional.interpolate(x,size=sp,mode='bilinear') #Resize
                  x = torch.cat((self.SkipConnections[i](SkipConFeatures[-1-i]),x), dim=1)
                  x = self.SqueezeUpsample[i](x)
#---------------------------------Final prediction-------------------------------------------------------------------------------
                x = self.FinalPrdiction(x) # Make prediction per pixel
                x = nn.functional.interpolate(x,size=InpImages.shape[2:4],mode='bilinear') # Resize to original image size
                Prob=F.softmax(x,dim=1) # Calculate class probability per pixel
                tt,Labels=x.max(1) # Find label per pixel
                return Prob,Labels
###################################################################################################################################

# nt=Net(12).cuda()
# #torch.save(nt,"tt.torch")
# #nt.save_state_dict("aa.pth")
# inp=np.ones((1,3,1000,1000)).astype(np.float32)
# inp=torch.autograd.Variable(torch.from_numpy(inp).cuda(),requires_grad=False)
# x=nt.forward(inp)






